{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The program allows us to read amazon review data and using different\n",
    "algorithms carry out a sentimental analysis and process the data\n",
    "\"\"\"\n",
    "#import packages required\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc\n",
    "#Categorizing stop words in one section\n",
    "stopWords = [] # create an empty list to collect the stopwords\n",
    "dataSet = []   #create an empty list to collect the data\n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    "# set up regular expressions\n",
    "\"\"\"\n",
    "    Do a regex search against all defined regexes and\n",
    "    return the key and match result of the first matching regex\n",
    "    \"\"\"\n",
    "regex_str = [\n",
    "    r'<[^>]+>',  # HTML tags\n",
    "    r\"(?:[a-z][a-z\\-_]+[a-z])\",  # words with - and '\n",
    "    r'(?:[\\w_]+)',  # other words\n",
    "    r'(?:\\S)'  # anything else\n",
    "]\n",
    "#Tokenization of strings\n",
    "tokens_re = re.compile(r'(' + '|'.join(regex_str) + ')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^' + emoticons_str + '$', re.VERBOSE | re.IGNORECASE)\n",
    "stemmer = PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "def initializeSystem():\n",
    "    stop = stopwords.words('english') + list(string.punctuation) + ['rt', 'via', 'i\\'m', 'us', 'it']\n",
    "    for x in stop:\n",
    "        stopWords.append(stemmer.stem(lemmatiser.lemmatize(x, pos=\"v\")))\n",
    "#Carry our preprocessing of review data\n",
    "def preprocess(s, lowercase=True):\n",
    "    tokens = tokens_re.findall(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else stemmer.stem(lemmatiser.lemmatize(token.lower(), pos=\"v\")) for\n",
    "                  token in tokens]\n",
    "    return tokens\n",
    "\n",
    "#Process strings with stop words and return\n",
    "def processString(string):\n",
    "    terms_stop = [term for term in preprocess(string) if\n",
    "                  term not in stopWords and len(str(term)) > 1 and not term.isnumeric()]\n",
    "    return terms_stop\n",
    "#Function to manage reading of files\n",
    "def loadFile(filePath):\n",
    "    fileRead = open(filePath, \"r\")  #Read input file\n",
    "    reader = csv.reader(fileRead, dialect='excel')  #Determine type of file\n",
    "    for row in reader:\n",
    "        temp = (row[1], row[-1])\n",
    "        dataSet.append(temp)\n",
    "    return dataSet\n",
    "\n",
    "def prepareSparseMatrix(convertedReviews, decisionAttributes):\n",
    "    sparseMatrix = []\n",
    "    for cr in convertedReviews:\n",
    "        newCr = [0] * len(decisionAttributes)\n",
    "        for word in cr:\n",
    "            if word in decisionAttributes:\n",
    "                index = decisionAttributes.index(word)\n",
    "                newCr[index] += 1\n",
    "            else:\n",
    "                pass\n",
    "        sparseMatrix.append(newCr)\n",
    "    return sparseMatrix\n",
    "#Function to convert reviews to readable strings\n",
    "def convertReviews(reviews):\n",
    "    convertedReviews = []\n",
    "    for a in reviews:\n",
    "        convertedReviews.append(processString(str(a).lower()))\n",
    "    return convertedReviews\n",
    "\n",
    "def getDecisionAttributes(convertedReviews):\n",
    "    toCount = []\n",
    "    decisionAttributes = []\n",
    "    for a in convertedReviews:\n",
    "        toCount.append(\" \".join(a))  #Join the strings\n",
    "    str1 = \"\"\n",
    "    for a in toCount:\n",
    "        str1 += \"\".join(a)\n",
    "    x = Counter(str1.split(\" \"))\n",
    "    for (k, v) in x.most_common(min(500, len(x))):\n",
    "        decisionAttributes.append(k)\n",
    "    return decisionAttributes\n",
    "#Function to train and process input data\n",
    "def model_data(training_data):\n",
    "    dtc = DecisionTreeClassifier(random_state=9, min_samples_split=5)\n",
    "    dtc.fit(training_data['data'], training_data['result'])\n",
    "\n",
    "    nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    nn.fit(training_data['data'], training_data['result'])\n",
    "\n",
    "    svc = SVC(C=100, kernel=\"linear\")\n",
    "    svc.fit(training_data['data'], training_data['result'])\n",
    "\n",
    "    rfc = RFC(n_estimators=10, criterion='entropy', max_depth=10, min_samples_split=5, bootstrap='true', random_state=None)\n",
    "    rfc.fit(training_data['data'], training_data['result'])\n",
    "\n",
    "\n",
    "    knc_map = knc(n_neighbors=15, weights='distance')\n",
    "    knc_map.fit(training_data['data'], training_data['result'])\n",
    "\n",
    "    gbc_map = gbc(n_estimators=150, verbose=0)\n",
    "    gbc_map.fit(training_data['data'], training_data['result'])\n",
    "\n",
    "    return {\n",
    "        'Decision Tree Classifier': dtc,\n",
    "        'Neural Networks': nn,\n",
    "        'Support Vector Machines': svc,\n",
    "        'Random Forest Classification': rfc,\n",
    "        'k Nearest Neighbours': knc_map,\n",
    "        'Gradient Boosting Classifier': gbc_map\n",
    "    }\n",
    "\n",
    "#Function to test the train data\n",
    "def test_models(test_data, models):\n",
    "    print(\"Prediction rating:\\n\")\n",
    "    for model in models:\n",
    "        prediction = models[model].score(test_data['data'], test_data['result'])*100.00\n",
    "        print(str(model) + \": \" + \"%.2f\" % prediction + \"%\")   #Print the results\n",
    "\n",
    "\n",
    "initializeSystem()\n",
    "#Calling all the functions used in the data\n",
    "#Load the test data \n",
    "training_data = loadFile(\"Data1.csv\")\n",
    "trainDataFeaturesReviews = pd.DataFrame(training_data, columns=[\"review\", \"rating\"])\n",
    "targetRating = (trainDataFeaturesReviews['rating'])\n",
    "targetReview = trainDataFeaturesReviews['review']\n",
    "trainReviews = convertReviews(targetReview)\n",
    "decisionAttributes = getDecisionAttributes(trainReviews)\n",
    "trainSparseMatrix = prepareSparseMatrix(trainReviews, decisionAttributes)\n",
    "dataFeatures = pd.DataFrame(trainSparseMatrix, columns=decisionAttributes)\n",
    "training_data = {\n",
    "    'data': dataFeatures,\n",
    "    'result': targetRating\n",
    "}\n",
    "\n",
    "#Load the test data\n",
    "test_data = loadFile(\"Data2.csv\")\n",
    "testDataFeaturesReviews = pd.DataFrame(test_data, columns=[\"review\", \"rating\"])\n",
    "testReview = testDataFeaturesReviews['review']\n",
    "testRating = testDataFeaturesReviews['rating']\n",
    "testSparseMatrix = prepareSparseMatrix(convertReviews(testReview), decisionAttributes)\n",
    "testDataFeatures = pd.DataFrame(testSparseMatrix, columns=decisionAttributes)\n",
    "test_data = {\n",
    "    'data': testDataFeatures,\n",
    "    'result': testRating\n",
    "}\n",
    "\n",
    "models = model_data(training_data)\n",
    "test_models(test_data, models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
